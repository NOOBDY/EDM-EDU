{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, values in convert_dict.items():\n",
    "    df[col] = df[col].map({value: i for i, value in enumerate(values)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>MonthlyRate</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>5993</td>\n",
       "      <td>1102</td>\n",
       "      <td>19479</td>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>5130</td>\n",
       "      <td>279</td>\n",
       "      <td>24907</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>2090</td>\n",
       "      <td>1373</td>\n",
       "      <td>2396</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>2909</td>\n",
       "      <td>1392</td>\n",
       "      <td>23159</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>3468</td>\n",
       "      <td>591</td>\n",
       "      <td>16632</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>36</td>\n",
       "      <td>2571</td>\n",
       "      <td>884</td>\n",
       "      <td>12290</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>39</td>\n",
       "      <td>9991</td>\n",
       "      <td>613</td>\n",
       "      <td>21457</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>27</td>\n",
       "      <td>6142</td>\n",
       "      <td>155</td>\n",
       "      <td>5174</td>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>49</td>\n",
       "      <td>5390</td>\n",
       "      <td>1023</td>\n",
       "      <td>13243</td>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>34</td>\n",
       "      <td>4404</td>\n",
       "      <td>628</td>\n",
       "      <td>10228</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1470 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  MonthlyIncome  DailyRate  MonthlyRate  HourlyRate  Education\n",
       "0      41           5993       1102        19479          94          2\n",
       "1      49           5130        279        24907          61          1\n",
       "2      37           2090       1373         2396          92          2\n",
       "3      33           2909       1392        23159          56          4\n",
       "4      27           3468        591        16632          40          1\n",
       "...   ...            ...        ...          ...         ...        ...\n",
       "1465   36           2571        884        12290          41          2\n",
       "1466   39           9991        613        21457          42          1\n",
       "1467   27           6142        155         5174          87          3\n",
       "1468   49           5390       1023        13243          63          3\n",
       "1469   34           4404        628        10228          82          3\n",
       "\n",
       "[1470 rows x 6 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the columns that have large std\n",
    "df = pd.read_csv('data.csv')\n",
    "# Age\n",
    "# MonthlyIncome\n",
    "# DailyRate\n",
    "# EmployeeNumber\n",
    "# MonthlyRate\n",
    "# HourlyRate\n",
    "df = df[['Age', 'MonthlyIncome', 'DailyRate', 'MonthlyRate', 'HourlyRate', 'Education']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['Education']\n",
    "X = df.drop(['Education'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "Y_pred_rf = rf_classifier.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17589393 0.22002293 0.2082885  0.20780742 0.18798722]\n"
     ]
    }
   ],
   "source": [
    "imp = np.array(rf_classifier.feature_importances_)\n",
    "print(imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Accuracy: 0.36054421768707484\n",
      "Random Forest Confusion Matrix:\n",
      "[[ 5  3 11  3  0]\n",
      " [ 1  8 29 25  0]\n",
      " [ 6  5 66 41  0]\n",
      " [ 2 10 42 27  0]\n",
      " [ 0  1  4  5  0]]\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.23      0.28        22\n",
      "           2       0.30      0.13      0.18        63\n",
      "           3       0.43      0.56      0.49       118\n",
      "           4       0.27      0.33      0.30        81\n",
      "           5       1.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.36       294\n",
      "   macro avg       0.47      0.25      0.25       294\n",
      "weighted avg       0.37      0.36      0.34       294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Random Forest model\n",
    "accuracy_rf = accuracy_score(Y_test, Y_pred_rf)\n",
    "conf_matrix_rf = confusion_matrix(Y_test, Y_pred_rf)\n",
    "classification_rep = classification_report(Y_test, Y_pred_rf, zero_division=1)\n",
    "\n",
    "print(f\"Random Forest Model Accuracy: {accuracy_rf}\")\n",
    "print(\"Random Forest Confusion Matrix:\")\n",
    "print(conf_matrix_rf)\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model Accuracy: 0.4013605442176871\n",
      "SVM Confusion Matrix:\n",
      "[[  0   0  22   0   0]\n",
      " [  0   0  63   0   0]\n",
      " [  0   0 118   0   0]\n",
      " [  0   0  81   0   0]\n",
      " [  0   0  10   0   0]]\n",
      "SVM Precision: 0.7597\n",
      "SVM Recall: 0.4014\n",
      "SVM F-score: 0.2299\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.00      0.00        22\n",
      "           2       1.00      0.00      0.00        63\n",
      "           3       0.40      1.00      0.57       118\n",
      "           4       1.00      0.00      0.00        81\n",
      "           5       1.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.40       294\n",
      "   macro avg       0.88      0.20      0.11       294\n",
      "weighted avg       0.76      0.40      0.23       294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# use PCA to reduce the dimensionality of the data\n",
    "# pca = PCA(n_components=2)\n",
    "# X_train_scaled = pca.fit_transform(X_train_scaled)\n",
    "# X_test_scaled = pca.transform(X_test_scaled)\n",
    "\n",
    "svm_classifier = SVC(kernel='linear', random_state=42)\n",
    "svm_classifier.fit(X_train_scaled, Y_train)\n",
    "# Make predictions on the test set\n",
    "Y_pred_svm = svm_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the SVM model\n",
    "accuracy_svm = accuracy_score(Y_test, Y_pred_svm)\n",
    "conf_matrix_svm = confusion_matrix(Y_test, Y_pred_svm)\n",
    "precision, recall, fscore, _ = precision_recall_fscore_support(Y_test, Y_pred_svm, average='weighted', zero_division=1)\n",
    "                    # weights = pd.concat(weights, pd.DataFrame([i, j, k, l, m, accuracy_svm, precision, recall, fscore], columns=['Age', 'MonthlyIncome', 'DailyRate', 'MonthlyRate', 'HourlyRate', 'Accuracy', 'Precision', 'Recall', 'F-score']))\n",
    "                    # weights.loc[len(weights.index)] = [i, j, k, l, m, accuracy_svm, precision, recall, fscore] \n",
    "print(f\"SVM Model Accuracy: {accuracy_svm}\")\n",
    "# print(svm_classifier.coef_)\n",
    "print(\"SVM Confusion Matrix:\")\n",
    "print(conf_matrix_svm)\n",
    "print(f\"SVM Precision: {precision:.4f}\")\n",
    "print(f\"SVM Recall: {recall:.4f}\")\n",
    "print(f\"SVM F-score: {fscore:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(Y_test, Y_pred_svm, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with RBF Kernel Model Accuracy: 0.3707482993197279\n",
      "SVM with RBF Kernel Confusion Matrix:\n",
      "[[  0   0  22   0   0]\n",
      " [  0   0  57   6   0]\n",
      " [  0   0 102  16   0]\n",
      " [  0   0  74   7   0]\n",
      " [  0   0  10   0   0]]\n",
      "SVM with RBF Kernel Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.00      0.00        22\n",
      "           2       1.00      0.00      0.00        63\n",
      "           3       0.38      0.86      0.53       118\n",
      "           4       0.24      0.09      0.13        81\n",
      "           5       1.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.37       294\n",
      "   macro avg       0.73      0.19      0.13       294\n",
      "weighted avg       0.54      0.37      0.25       294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train SVM with RBF kernel model\n",
    "svm_rbf_classifier = SVC(kernel='rbf', random_state=42)\n",
    "svm_rbf_classifier.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "Y_pred_svm_rbf = svm_rbf_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the SVM with RBF kernel model\n",
    "accuracy_svm_rbf = accuracy_score(Y_test, Y_pred_svm_rbf)\n",
    "conf_matrix_svm_rbf = confusion_matrix(Y_test, Y_pred_svm_rbf)\n",
    "classification_rep_svm_rbf = classification_report(Y_test, Y_pred_svm_rbf, zero_division=1)  # Adding zero_division parameter\n",
    "\n",
    "print(f\"SVM with RBF Kernel Model Accuracy: {accuracy_svm_rbf}\")\n",
    "print(\"SVM with RBF Kernel Confusion Matrix:\")\n",
    "print(conf_matrix_svm_rbf)\n",
    "print(\"SVM with RBF Kernel Classification Report:\")\n",
    "print(classification_rep_svm_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model Accuracy: 0.3197278911564626\n",
      "Decision Tree Confusion Matrix:\n",
      "[[ 8  5  7  0  2]\n",
      " [ 4 13 22 20  4]\n",
      " [11 14 49 42  2]\n",
      " [ 9 13 31 24  4]\n",
      " [ 1  4  2  3  0]]\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.24      0.36      0.29        22\n",
      "           2       0.27      0.21      0.23        63\n",
      "           3       0.44      0.42      0.43       118\n",
      "           4       0.27      0.30      0.28        81\n",
      "           5       0.00      0.00      1.00        10\n",
      "\n",
      "    accuracy                           0.32       294\n",
      "   macro avg       0.24      0.26      0.45       294\n",
      "weighted avg       0.33      0.32      0.36       294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Decision Tree model\n",
    "tree_classifier = DecisionTreeClassifier(random_state=42)\n",
    "tree_classifier.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "Y_pred_tree = tree_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the Decision Tree model\n",
    "accuracy_tree = accuracy_score(Y_test, Y_pred_tree)\n",
    "conf_matrix_tree = confusion_matrix(Y_test, Y_pred_tree)\n",
    "classification_rep_tree = classification_report(Y_test, Y_pred_tree, zero_division=1)  # Adding zero_division parameter\n",
    "\n",
    "print(f\"Decision Tree Model Accuracy: {accuracy_tree}\")\n",
    "print(\"Decision Tree Confusion Matrix:\")\n",
    "print(conf_matrix_tree)\n",
    "print(\"Decision Tree Classification Report:\")\n",
    "print(classification_rep_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Model Accuracy: 0.35034013605442177\n",
      "Gradient Boosting Confusion Matrix:\n",
      "[[ 4  0 14  4  0]\n",
      " [ 2  4 32 25  0]\n",
      " [ 4  6 75 32  1]\n",
      " [ 2 10 49 20  0]\n",
      " [ 0  0  8  2  0]]\n",
      "Gradient Boosting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.18      0.24        22\n",
      "           2       0.20      0.06      0.10        63\n",
      "           3       0.42      0.64      0.51       118\n",
      "           4       0.24      0.25      0.24        81\n",
      "           5       0.00      0.00      1.00        10\n",
      "\n",
      "    accuracy                           0.35       294\n",
      "   macro avg       0.24      0.23      0.42       294\n",
      "weighted avg       0.30      0.35      0.34       294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Gradient Boosting model\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "gb_classifier.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "Y_pred_gb = gb_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the Gradient Boosting model\n",
    "accuracy_gb = accuracy_score(Y_test, Y_pred_gb)\n",
    "conf_matrix_gb = confusion_matrix(Y_test, Y_pred_gb)\n",
    "classification_rep_gb = classification_report(Y_test, Y_pred_gb, zero_division=1)  # Adding zero_division parameter\n",
    "\n",
    "print(f\"Gradient Boosting Model Accuracy: {accuracy_gb}\")\n",
    "print(\"Gradient Boosting Confusion Matrix:\")\n",
    "print(conf_matrix_gb)\n",
    "print(\"Gradient Boosting Classification Report:\")\n",
    "print(classification_rep_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-Nearest Neighbors Model Accuracy: 0.2891156462585034\n",
      "k-Nearest Neighbors Confusion Matrix:\n",
      "[[ 0  7 11  4  0]\n",
      " [11 13 23 16  0]\n",
      " [12 21 59 26  0]\n",
      " [ 7 23 38 13  0]\n",
      " [ 2  2  3  3  0]]\n",
      "k-Nearest Neighbors Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      1.00        22\n",
      "           2       0.20      0.21      0.20        63\n",
      "           3       0.44      0.50      0.47       118\n",
      "           4       0.21      0.16      0.18        81\n",
      "           5       1.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.29       294\n",
      "   macro avg       0.37      0.17      0.37       294\n",
      "weighted avg       0.31      0.29      0.36       294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train k-Nearest Neighbors model\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "knn_classifier.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "Y_pred_knn = knn_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the k-Nearest Neighbors model\n",
    "accuracy_knn = accuracy_score(Y_test, Y_pred_knn)\n",
    "conf_matrix_knn = confusion_matrix(Y_test, Y_pred_knn)\n",
    "classification_rep_knn = classification_report(Y_test, Y_pred_knn, zero_division=1)  # Adding zero_division parameter\n",
    "\n",
    "print(f\"k-Nearest Neighbors Model Accuracy: {accuracy_knn}\")\n",
    "print(\"k-Nearest Neighbors Confusion Matrix:\")\n",
    "print(conf_matrix_knn)\n",
    "print(\"k-Nearest Neighbors Classification Report:\")\n",
    "print(classification_rep_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.3401360544217687\n",
      "Confusion Matrix:\n",
      "[[ 0  0 20  2  0]\n",
      " [ 0  0 52 11  0]\n",
      " [ 0  0 90 28  0]\n",
      " [ 0  0 71 10  0]\n",
      " [ 0  0  9  1  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train logistic regression model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "Y_pred = logreg.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "print(f\"Model Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Model Accuracy: 0.3469387755102041\n",
      "Naive Bayes Confusion Matrix:\n",
      "[[ 0  0 19  3  0]\n",
      " [ 0  0 50 13  0]\n",
      " [ 0  0 90 28  0]\n",
      " [ 0  0 69 12  0]\n",
      " [ 0  0  9  1  0]]\n",
      "Naive Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.00      0.00        22\n",
      "           2       1.00      0.00      0.00        63\n",
      "           3       0.38      0.76      0.51       118\n",
      "           4       0.21      0.15      0.17        81\n",
      "           5       1.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.35       294\n",
      "   macro avg       0.72      0.18      0.14       294\n",
      "weighted avg       0.53      0.35      0.25       294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Naive Bayes model\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "Y_pred_nb = nb_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the Naive Bayes model\n",
    "accuracy_nb = accuracy_score(Y_test, Y_pred_nb)\n",
    "conf_matrix_nb = confusion_matrix(Y_test, Y_pred_nb)\n",
    "classification_rep_nb = classification_report(Y_test, Y_pred_nb, zero_division=1)  # Adding zero_division parameter\n",
    "\n",
    "print(f\"Naive Bayes Model Accuracy: {accuracy_nb}\")\n",
    "print(\"Naive Bayes Confusion Matrix:\")\n",
    "print(conf_matrix_nb)\n",
    "print(\"Naive Bayes Classification Report:\")\n",
    "print(classification_rep_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
